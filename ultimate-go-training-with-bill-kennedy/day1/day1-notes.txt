# Day 1: Basic Go Data Semantics

How do we turn this piece of code into an engineering product?
    * Lines of code is a good metric for a the success of a team.
    * There are exceptions to every rule. Engineering is about knowing _when_ to take exceptions. 

2 foundational guidelines: 
    1. do not make things easy to do, make them easy to understand (even if it is a bit tedious)
    2. every encapsulation must define a new semantic/behavior where one is absolutely precise

Go is NOT perfect:
    * too many ways to declare variables (standards? JUST BE CONSISTENT! in Go, every byte gets set to zero-value)
        * zero-value definition: `var count int`
        * package-level variables: `var global string = "hello` //must have keyword if outside of definitions
        * short variable declaration: `count := 10`
    * if you are using a value definition, always use value-semantic construction & leverage the & operator
        * if you are constructing on a return, you can use pointer-semantic construction
    * if people write in tight-loops (i.e. no function calls), then scheduling/garbage collection can't run

Intro: https://github.com/ardanlabs/gotraining/blob/master/topics/go/README.md
* industry where performance became the highest priority and not the maintainability of the code we're writing
* "The software business is one of the few places we teach people to write before we teach them to read." - Tom Love (inventor of Objective C)
* mental models: You must constantly make sure your mental model of your projects are clear. When you can't remember where a piece of logic is or you can't remember how something works, you are losing your mental model of the code. This is a clear indication that refactoring is a must. Focus time on structuring code that provides the best mental model possible and code review for this as well.
    * https://en.wikipedia.org/wiki/The_Magical_Number_Seven,_Plus_or_Minus_Two
* productivity vs performance: the belief that the hardware can make slow code faster is wrong, need to have perofrmance be top priority
    * hardware hasn't really changed in the last 2 decades
    * how can you get latency to work for you?
* correctness vs performance: optimizing the code for correctness, and then let tooling take care of performance?
    * "Make it correct, make it clear, make it concise, make it fast. In that order." - Wes Dyer
* code reviews: hese four major categories are the basis for code reviews and should be prioritized in this order: Integrity, Readability, Simplicity and then Performance.
    1. Integrity: we need to become serious about reliability
        * the software we write affects people's lives
        * need accuracy, consistency, and efficiency
        * micro (every integer is thought of when allocating/reading/writing memory) vs macro (data transformation problems) integrity
        * write less code: it will have less bugs and be more correct (1 bug for every 20 lines of code)
        * go is a data-oriented programming language
        * error handling: 92% of failures could have been fixed by better error handling
            * "Failure is expected, failure is not an odd case. Design systems that help you identify failure. Design systems that can recover from failure." - JBD
    2. Readability: we must structure our systems to be more comprehensible 
        * this word has a different definition for each programming language
        * subjective: an avg. developer has a clear understanding of the code to be able to fix a production bug (above-avg developers have one job: to be a coach, not implement more difficult code)
        * non-subjective: readable code does not hide the cost of the trade-offs we're taking
    3. Simplicity: we must understand that simplicity is hard to design and complicated to build
        * how can we hide complexity without hiding readability?
    4. Performance: we must compute less to get the results we need
        * performance does matter, but it should not ever outweigh readability 

Pointers: https://github.com/ardanlabs/gotraining/blob/master/topics/go/language/pointers/README.md 
Value-of exercise: https://play.golang.org/p/9kxh18hd_BT  
* mechanics vs semantics:
    * mechanics are how things are implemented (change all the time)
    * semantics are understanding the behaviors
    * ex: go playground is 32-bit (vs 64-bit), so semantics will be the same but mechanics may change - single threaded env
        * "int" will use the most efficient integer type for the architecture (instead of hardcoding int64, int16, etc)
        * int and address pointers will all be the same size
* all you need to know is one layer below where you are coding
* Goroutine is an application level thread (co-routine) that gets attached to ever OS thread/processor in the computer
    * The machine of the processor gets a stack and then the Gorountine also gets its own stack
    * Go allocates a 2K byte stack - paths of execution need to be as light-weight as possible so that many Goroutines can run
    * Goroutine is locked in timeout in the stackframe (takes frame off stack), only memeory it can read-write is in that stackframe
    * If we can isolate the mutations in small-amounts of memory, we can handle the problems easier
    * data transformations (new function definitions) get called in separate stackframes & will operate on it's own copy of the data
* When the data is APPLICATION-WIDE, we can't use value semantics, we HAVE TO USE pointer semantics
    * we do want to limit this because it causes bugs, but if used correctly, it will help with making the code easier to maintain/read
* TYPE is everything!
    * type derives 2 pieces of info: how much memory to write and what data it implements (how to read it)
    * we want to know that the data is shared and _what_ that data is

Garbage collection: https://play.golang.org/p/n9HijcdZ3pT 
* Writing multi-threaded software is really hard, so Go tries to make some of that easier.
* escape analysis is where the compiler tries to determine where the value should be constructed/analyzed
    * does this value get to be constructed on the stack or on the heap?
    * looks at how something is shared - construction tells you nothing
    * if we're sharing data down the call stack, that's okay ( we can share down with integrity - line 45)
    * sharing data up is not okay (line 47) because the frame would get cleaned up, so instead Go is going to escape and the value will get constructed on the heap
    * "construct what you need and I will determine where it goes and how you can access it" - hiding the complexity of memory management
    * there is a COST of heap allocation (will show up in a profiler) because we're sharing up the call-stack
        * by defining the user `u := &user{}` instead of returning `&u`, we take away readability of cost, since you now look at 2 lines of code to determine the sharing of data (pointer-semantic construction)
        * use value-semantic construction when you are doing value definitions
    * ecape-analysis report: `go build -gcflags -m=2`
* ownership: the function that performs the function is the one that owns the value, so does something else need the value of the function if returned?
* more on heap allocation:
    * stackframes are calculated at compile-time but some types are not known and automatically put to the heap
        * ex: slices with variable lengths are not known at compile-time and may automatically become heap-allocation
        * if the slice length is hardcoded, it can be allocated in the stack
    * compiler speed is more important in Go (won't see tail-recursive performance improvements)
    * what happens if we run out of memory in the 2K stack? 
        * Go does not use segmented stacks, instead it uses **contiguous stacks** 
        * if the stack has to grow, the new stack of 2-times the size will be created and values will be copied over to the new location
    * garbage collector wants to minimize size of the heap as much as possible and it wants to make sure the application-throughput latency is as minimal as possible
        * how can we be mechanically sympathetic with the garbage collector?
        * Go's garbage collector will kick off as soon as 4megs of memory is allocated across the field of heap memory
        * 3 phases of garbage collection:
            1. mark start - stop the world STW phase (no applcation work getting done - wants to keep this down to 100 microseconds or less)
            2. Marking - concurrent phase (down in CPU throughput but still running routines) 
            3. mark terminate - STW
        * ex: if you have 4-threaded Go program, you have 4 Processors with a Go Routine each (with other Go apps queued up)
            * 100% CPU = 4 Goroutines
            * write-barrier flag: allows concurrent access in the next phase to NOT cause any integrity issues while application work is getting done
        * gcs are triggered during breaks in function calls - so no functions, no garbage collection
        * for every 4 goroutines, there will be 1 dedicated to a GC (so 8 threads = 2 GCs) - preimptive GCing, but now we're down to 75% of cpu throughput
        * Marking - concurrent phase:
            * start at top of stack and work down to active frame, find pointers that point to the heap, and then mark everythign white; if we find root values, we turn it grey and put it in a queue; pull grey values out of queue, paint it black, and see if there is anything else it has (and repeat grey queueing process)
            * now we have only black or white flags on all of our variables
        * One single knob: GC percent, GOGC=100 (default) - stands for percentage - don't play with this knob! but we will tomorrow
            * tells pacing algo when the next GC should start
            * you can also set this to "off" - in which GC will not run
                * good for benchmarking? small lambda functions/cron jobs that don't run very long
                * don't want to shut this off for long-running services probably ever
            * https://www.ardanlabs.com/blog/2018/12/garbage-collection-in-go-part1-semantics.html - Figure 12
                * heap is growing while marking is going on, so GC doesn't want heap to grow more than an extra X-megs
            * Mark-assist could take up another processor (down to 50% cpu throughput), so GC will kick of earlier than the GOGC percentage to try to limit that time that takes up the CPU
        * Reduce GC? don't write that much to the heap - throughput will go up
        

Caching: https://github.com/ardanlabs/gotraining/tree/master/topics/go/testing/benchmarks/caching
And: https://github.com/ardanlabs/gotraining/tree/master/topics/go/language/arrays
* Benchmarking: the machine must be idle to be able to run a pure benchmark test
* Main memory is so slow to access that you should assume it's not even there - caching allows for a lot faster data retrieval
* **Performance is about how efficiently you get data into the Processor.**
* Caches: 
    * L1 - 64KB Cache (Per Core), 4 cycles of latency at 1.3 ns, Stalls for 16 instructions
    * L2 - 256KB Cache (Per Core), 12 cycles of latency at 4 ns, Stalls for 48 instructions
    * L3 - 8MB Cache, 40 cycles of latency at 13.3 ns, Stalls for 160 instructions
    * Main Memory - 100 cycle of latency at 33.3 ns (~100ns), Stalled for 400 instructions
    * Translation Lookaside Buffer (TLB) - virtual address mapper back to the physical memory (OS messaging page and offsets)
        * if data is not in the TLB, then OS has to scan all its tables and maybe even the VM paging tables, which is very slow
* Cache line: moves data from main memory to cache, and pull in the cache line from Machine to L1 or L2 (and a copy to L3, as well)
    * hardware runs software programs, one is a prefetcher (tries to pull cache lines into the hardware before they are needed, but they need help)
        * we have to write code to allow prefetchers to know about what data is needed before it is actually needed
        * write code that creates predictables access patterns to memory to help pull that data in 
        * allocate contiguous blocks of memory and then walk down that data in linear-traversal strides; ARRAYS!
* Arrays will beat most everything for speed and is most important data structure as it relates to the hardware.
* Go does NOT have a Virtual Machine, it uses Runtime
    * linked lists are not efficient (object-oriented) but JVM is able to convert linked lists efficiently into row-traversed data
    * Go just gives array, slice (slices are vector arrays under the hood), and maps (hash algo with bucketing system and constantly make data contiguous) to make code mechanically sympathetic
        * slice is the besttttttt for Go

Arrays: https://github.com/ardanlabs/gotraining/blob/master/topics/go/language/arrays/example1/example1.go
* an assignment operation is a write operation
* for/ranges - always use these if iterating over the whole array, but there are 2 ways to do this (both value and pointer semantics)
    * value semantic: `for i, fruit := range fruits {}` //becomes copy of string in the array
    * pointer semantic: `for i := range fruits {}`
* data types:
    * strings (numerics, bools) are designed to fit value-semantics to move data around that program; if on heap, that is NOT productive
    * fields/structs are user defined and should also be value-semantic based
    * derived/reference types (arrays, pointers, slices, maps, channels, functions, interfaces) are all pointer semantic types
    * exceptions: 
        * Go has the concept of `nil` - zero-value for reference types
        * Go does NOT have concept of `null` - absence of value
        * how do you handle an absence of value in Go?
            * you can use SQL types OR
            * pointer-semantics - may have a pointer of type string in a struct to use specifically in a db

Slices: https://github.com/ardanlabs/gotraining/tree/master/topics/go/language/slices
* when working with slices, everyone gets their own copy of the slice (value semantics), but when reading/writing, we use pointer semantics
* you should always pass copies of data structures, but can get away with using pointer semantics in map/slice if using decode/unmarshall
* A slice is a descriptor of an array segment. It consists of:
    1. a pointer to the array
    2. the length of the segment
    3. its capacity (the maximum length of the segment)
* `var data []string` gives the zero-value of this slice (stores [nil, 0, 0] and returns "null"); `data := []string{}` does NOT give you zero-value, but instead an empty value
    * collections are allowed to be empty (stores [*, 0, 0] and returns "[]")
    * but there's an empty pointer? what does it point to? 
        * Go has another special type, the empty struct - `var es struct{}` - zero-allocation type
        * part of the Go runtime (global variable)
        * all of these values will have the same address in memory with zero allocation of data
* append built-in function: 
    * `data = append(data, value)` - reference types use value semantics to move around the program
    * takes in a copy of the slice and then returns the safely mutated copy of the data back to the original, that then gets mutated safely
* memory leaks in Go:
    * when there is a Goroutine holding a reference to a piece of memory in the heap and locking it in from getting it cleaned up even though it's not being used
    * the value that might be overallocating is not the thing that might be leaking
    * not possible to write a sustainable program to trace memory leaks in Go
    * until GC tells you that you have a memory leak, we don't have one
    * what to do if you do get a memory leak:
        1. #1 cause - playing with concurrency and creating extra goroutines (and they don't terminate)
        2. using a map as an inproc cache - at some point, you need to delete keys
        3. find context package when to call cancel
        4. forgetting a close-method on an API - start commenting out code
        5. multiple collections being joined
* Go will double capacity when we run out of space in a slice (under 1000 elements), or it will grow at 25% after that
* side effects happen because all mutations are occuring with pointer semantics. some examples:
    * reference parts of a slice: [a:b] //not including b, or [a:a+len]
    * backing arrays: `slice2 := slice1[2:4]; slice2[0] = "CHANGED"`; if you mutate data in a slice that was derived from another slice, then you can alter BOTH slices with one mutation call
        * even worse side effect: `slice2 := slice1[2:4]; slice2 = append(slice2, "CHANGED")` will STILL update behind the scenes in the append call
        * fix: you can add a capacity call to the definition: `slice2 := slice1[2:4:4]` OR do a `copy(slice3, slice1)` just in case
    * append can cause the backing array to be replaced but the parent pointer not pointing to the correct, new backing array
        * any call to append _can_ replace the backing array
        * we should instead include structs instead so when you update a user, you update the underlying structs




