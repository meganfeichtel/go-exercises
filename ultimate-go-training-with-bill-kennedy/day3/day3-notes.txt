# Day 3: Building Web Services and Macrodevelopment


Tooling: 
* Only use it when you need it
* using tooling, you don't have to guess when you're coding

Stack Traces: https://github.com/ardanlabs/gotraining/blob/master/topics/go/profiling/stack_trace/example1/example1.go
* vs. https://github.com/ardanlabs/gotraining/blob/master/topics/go/profiling/stack_trace/example2/example2.go
    * everything is backwards in memory - everything is just reversed
    * we passed [true, false, true, 25] -> the line reads (0xc019010001) -> (0xc019(25) 01(T) 00(F) 01(T))
    * ever seen in a stack trace? +0x39 -> instruction pointer offset of line of asssembly
    * gotip tool objdump -S(give assembly representation of binary) -s(filter fnx) main.go

Tracing:
* https://github.com/ardanlabs/gotraining/blob/master/topics/go/profiling/trace/trace.go
* do a basic solution for frequency of a string within a bunch of news articles (in about 4-5 seconds)
* can we make this more efficient? 
    * `pprof.StartCPUProfile(os.Stdout)` - starts a CPU profile (day1 we did the benchmarks)
        * make sure you defer the stop: `defer pprof.StopCPUProfile()`
    * the first run of this took about 5 seconds (a little longer)
    * but with the output (time ./trace > p.out), we can now use a new tool: `gotip tool pprof [-http :3000] p.out`
        * in tool: `list freq`: flat column is flat cost (what's costing in performance) and the cumulative is the sum of cost over each instruction
            * line 59 is taking the slowest part, so focus on that
        * `web freq`: gets a call path diagram
            * to be able to open graph, you must have graphviz
            * the red paths are to tell you where to look more into - the system call is slowing us down, so it's in the machine, not the code efficiency
* sometimes it's about what's not happening, instead of what this tool says is happening - we need a tracer
    * comment out the CPU profile, and instead use `trace.Start()` and `trace.Stop`
    * `gotip tool trace t.out`
        * the gotip trace tool only works in Chrome lol
        * in trace/: can see the goroutines and heap down to the microsecond
        * heap profile:
            * the GC is maintaining a 4meg heap and the pacing algo is respecting that gogc number if the heap is climbing and then going back to bottom
            * also shows how much of the memory is transient - bc reading whole file in mem, decodes it, processes it, and then doesn't need it anymore (very heavy on the memory)
        * go into one of the GC moments we can see all the things we talked about the first day (STW, Marking, dedicated, etc), and then the reallocation of memory right after the GC
        * small lines under the runtime indicate system calls
        * this also shows we're only using 1 thread to do application work: one goroutine at any given time (as well as the GCs), even though we have access to more threads
            * but the order of the file processing doesn't matter in this algo - CONCURRENCY!
        * double clicking on something allows you to see metrics for all the things with the same label (dragging and creating a windo allows you to select a few)
            * 2-3% of the full time was used for GC - because it's leveraging so much CPU capacity that we're not using and maintained a 4meg heap (really small)
* simplest solution to make this concurrent? fanout pattern, give each file its own goroutine (may not scale well)
    * `freqConcurrent` - use the goroutines for every file
    * use atomic number for race condition of the `found` metric
    * cache coherency problem: the found will be copied over to all cores and any update will cause latency (mark other copies as dirty)
        * so we can create a local found variable in the goroutine and write a defer function that writes the local found variable back to the original found
    * this was easy BECAUSE we already had the sequential version
* `freqNumCPU`:
    * extra level of complexity: we've added a channel now
    * this function is much more mechanically sympathetic because it's only writing to `found` the # of core times (8/16)
    * runs really well with a 40meg heap and the cpu balanced by the computer's hardware requirements

MemCPU: https://github.com/ardanlabs/gotraining/blob/master/topics/go/profiling/memcpu/stream.go 
* search the entire internet for "elvis" and capitalize the E
* gotip test -bench . -benchtime 3s -benchmem -memprofile m.out //the memprofile will give us a memory profile that we can use `pprof` to evaluate
    * this test also leaves a test binary - `gotip tool pprof [stream.test - only if you want binary instructions] m.out`
        * Type: alloc_space (other is live heap space)
    * `gotip tool pprof -noinlines m.out`: compiler optimizations
        * output will now matche the weblist default data (shows compiler optimizations) instead of the list default data (doesn't have compiler optimizations on)
        * `list algOne`:
            * line 83 and 89 are flat allocations - these two rows are causing this
    * to know why, we need to look at the compiler - ecape analysis report   
        * gotip test -bench . -benchtime 3s -benchmem -memprofile m.out --gcflags -m=2
        * line 83 (NewBuffer) now shows up in that compiler report: 
            * compiler says let's not make function call but instead take code out of function, inline it directly, and forget the function call
            * making a function call in go is very expensive - lots of things happen, stack grows, context switches, memory copying, etc.
            * if clockcycles mattered, you would write all code in one function - but the compiler is here to help us optimize this without having to call a function under the hood
            * also NewBuffer is using pointer semantics - heap allocation - if call gets inlined and there's no function call there is NOT an allocation

Scavenger: run in the background and release memory back to the os/program
    * originally it wasn't very aggressive (memory outages), so they rewrote it and now it's super aggressive
    * this is bad for GC trace output because it takes over the screen, so run: `GODEBUG=gctrace=1 ./project 2> >(grep -v 'scvg') > /dev/null`
* Debugging tool: https://github.com/ardanlabs/gotraining/tree/master/topics/go/profiling/project 
    * localhost:5000/debug/pprof/
    * gotip took pprof http://localhost:5000/debug/pprof//allocs will download that profile to the local
    * `top 40 -cum` -> gives cumulative allocation for top 4 functions

Other tools/frameworks? 
* bgo - lots of apps in china use this
* buffalo.io - the rails for go, good for web apps

Application design: https://github.com/ardanlabs/service 
* going to be making our own edits: https://github.com/meganfeichtel/service 
* starter kit for go dev projects - clone and run 
* writing a webservice (crud-based)
* every decision at a macro-level should be to handle bugs in production
* Go says: 
    * the source tree that you are putting together, you are no longer building a monolithic app where folders are used to utilize source code
    * you are building a static set of apis that come together to form an applications
    * every folder in the source tree that actually represents a static codebase - this package of code acts as a firewall (microservices)
    * every time we add a folder, what is this package/API's purpose? 
    * if there are packages called utils, common, package of types, etc - because that point of dependency is going to cause the project to not be able to grow
    * you want DISTINCT, CONCRETE, PYSHICAL apis
* Type system: 1 purpose - allow data to flow in and out of an API
    1. to flow in - based on what it is (concrete) or what it does (interface)
    2. to flow out - always returns the concrete data (does not pre-decouple data for the caller)
        * return type should not be an interface, the caller can do that for themselves
        * exception is error handling
* Less packages are more: start with larger packages and then discover where it could be broken down for simplicity/need
    * all developers at Go work out of 1 repo - why there is one GOPATH - now because of modules, we're not actualy bound to this anymore
    * it's also very opinionated _except_ about project structures 
        * make sure package you add on Monday, you would make the same exact decision of where to put it on Friday - or else very difficult to maintain a mental model
        * project structure has 3 parts:
            1. application layer packages - start up, shut down, request/response, maybe some containment
                * also policies (like logging)
            2. business layer - talking to dbs, biz rules
            3. foundational packages - marshalling
                * can't and shouldn't be logging
* for every project you are working on, bind it to a single repo (not 1 binary)
    * when we talk about microservices, they're solving productivity issues, so only break things up if velocity is slowing
    * hierarchy should serve one purpose: to make it easier to maintain an mental model of the code
    * 2 folders: 
        1. cmd/ - have other folders, one for each binary we're building, application layer packages
            1. add an `internal/` to these: compiler gives another layer of protection because it is the only project that can access these packages
        2. internal/ - business layer packages, shouldn't have packages inside of packages
            1. platform - anything that is business that isn't applicational
    * we can also find bad imports with this model - imports can go down but never up!
* create a kit repo/project at the company level - team's standard library
    * all the foundational packages should live there and be used as a 3rd party dependency
    * these have the highest level reusability, thus they need to be careful about policies being set

Modules:
* GOPATH mode or module mode - you don't want to switch to modules if you start with GOPATH mode
    * when you have a go.mod file, that now becomes the GOPATH for the project, thus needs to be at the root at that repo
* go mod init
* Go's integrated system for dependency managements: versioning, durability, security for code you're working with
    * the go.mod file will only contain the direct dependencies that this project is importing
    * NOT a complete manifest of the dependencies that you are using
* go please server - one instance for every VS codebase that you are running
    * it reads the module cache that is on your machine
    * it doesn't look at disk again, only working off of its cache - doesn't know to reload its internal cache
    * `go clean -modcache`
* version is in the go.mod path for when we get to a Go 2.X version

Logs:
* if they are just for logging, then we should just use the go built-in packages for logging to stdout
* we need readability and signaling for when things are both good and bad
* don't write loggers that write to anywhere but standard out
* logging levels: you either need this information or you don't - it's either signal or noise
* don't use singletons for logging - there are NO global variables, if anything needs to be logged, it should be given in the function

Configuration:
* questions:
    * can we restart the application when the config changes? do your best to say yes
    * where should we store our configurations? 
    * its a "crime" for a service to crash on startup because something wasn't configured
    * also bad if the operator of the service cannot install it because they didn't know all the toggles in the config
    * this all happens when you allow any package to hit configurations
* rules:
    * any source code file to use configuration should be main.go
    * all configs will be retrieved from main and be passed down to other packages/functions
    * every config value must have a default and MUST work for the development environment (cloen repo and run)
    * the more of the defaults that work in staging and production, the better your life is
    * the operator trying to install and run your service should be able to type `--help` to see all config options, their defaults, and how they overwrite them (including the flags)
    * you can also see all the configs in main.go

Dependencies:
* MVS: doesn't always select latest and greatest - ALWAYS latest, but not necessarily the greatest
    * preiously used SAT solvers - latest, greatest version of a dependency compatible with the project
* Go looks at the module mirror in Google for a proxy server, and that server could return that version of the library
    * if it doesn't have that version of that repo, it will clone the repo down from direct (github), captures it, and creates a zip file of that version number
* You _can_ always go direct, stand up your own module mirror (athens is open source), set env variables (GONOPROXY) to turn that lookup off in Google's proxy
* go.sum file: 
    * the checksum db that gives a layer of durability of detection - it will generate hash codes and double check that the code hasn't changed
* `go mod tidy` - cleans imports for you, keeps go.mod file clean, esp when you've been playing with imports

Global variable rules:
* order of initialization of variable doesn't matter
* it doesn't depend on a configuration change
* only source code file that touches the variable is the one it is declared in

Monitoring/debugging:
* "// Start Debug Service" section - the goroutine in the background that binds the debugger to the host port
* exvarmon is a tool that takes the debug server and is able to wrap it with a service
* Gorillamux - most common service; but Bill is going to be using the HTTP Tree router
* didn't give a clean shutdown to the goroutine, but when it comes to the production restapi, can't just do a kill9
    * need load shedding - shut down and wait a certain amount of time for the requests to finish without accepting any more

Checking the service start up/shut down:
* start service up, and shut it down
* start it up, run some load, and then make sure it shuts down (or you have a data race)
* start it up, send some load, shut it down while there is still load, and make sure it shuts down without timing out (or you have a data race)

Routers: 
* packages shouldn't contain things _but_ routes.go will be one of the exceptions, since it will only be used by one package
* violating own rule: no function should return decoupled data, but the routes.go func is an interface type
    * but we're not responsible for doing this decoupling

APIs:
* every function should be able to succeed without errors with nothing in the context (that isn't absolutely required)

Middleware:
* want to write out a log for every request made to the API
* setting business policy to the web frameworks without breakin the rules of setting policy in foundational code
* `mw ...Middleware` means that the parameter is optional - only do this when it is 1:many relationship


Contact:
* https://education.ardanlabs.com/ if you want more 
* best way to get in touch with bill is through email: bill@ardanlabs.com
* "Go in Action" book - good for syntax
* Blog: https://www.ardanlabs.com/blog/ 