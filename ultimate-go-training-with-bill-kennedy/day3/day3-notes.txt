# Day 3: Building Web Services and Macrodevelopment


Tooling: 
* Only use it when you need it
* using tooling, you don't have to guess when you're coding

Stack Traces: https://github.com/ardanlabs/gotraining/blob/master/topics/go/profiling/stack_trace/example1/example1.go
* vs. https://github.com/ardanlabs/gotraining/blob/master/topics/go/profiling/stack_trace/example2/example2.go
    * everything is backwards in memory - everything is just reversed
    * we passed [true, false, true, 25] -> the line reads (0xc019010001) -> (0xc019(25) 01(T) 00(F) 01(T))
    * ever seen in a stack trace? +0x39 -> instruction pointer offset of line of asssembly
    * gotip tool objdump -S(give assembly representation of binary) -s(filter fnx) main.go

Tracing:
* https://github.com/ardanlabs/gotraining/blob/master/topics/go/profiling/trace/trace.go
* do a basic solution for frequency of a string within a bunch of news articles (in about 4-5 seconds)
* can we make this more efficient? 
    * `pprof.StartCPUProfile(os.Stdout)` - starts a CPU profile (day1 we did the benchmarks)
        * make sure you defer the stop: `defer pprof.StopCPUProfile()`
    * the first run of this took about 5 seconds (a little longer)
    * but with the output (time ./trace > p.out), we can now use a new tool: `gotip tool pprof [-http :3000] p.out`
        * in tool: `list freq`: flat column is flat cost (what's costing in performance) and the cumulative is the sum of cost over each instruction
            * line 59 is taking the slowest part, so focus on that
        * `web freq`: gets a call path diagram
            * to be able to open graph, you must have graphviz
            * the red paths are to tell you where to look more into - the system call is slowing us down, so it's in the machine, not the code efficiency
* sometimes it's about what's not happening, instead of what this tool says is happening - we need a tracer
    * comment out the CPU profile, and instead use `trace.Start()` and `trace.Stop`
    * `gotip tool trace t.out`
        * the gotip trace tool only works in Chrome lol
        * in trace/: can see the goroutines and heap down to the microsecond
        * heap profile:
            * the GC is maintaining a 4meg heap and the pacing algo is respecting that gogc number if the heap is climbing and then going back to bottom
            * also shows how much of the memory is transient - bc reading whole file in mem, decodes it, processes it, and then doesn't need it anymore (very heavy on the memory)
        * go into one of the GC moments we can see all the things we talked about the first day (STW, Marking, dedicated, etc), and then the reallocation of memory right after the GC
        * small lines under the runtime indicate system calls
        * this also shows we're only using 1 thread to do application work: one goroutine at any given time (as well as the GCs), even though we have access to more threads
            * but the order of the file processing doesn't matter in this algo - CONCURRENCY!
        * double clicking on something allows you to see metrics for all the things with the same label (dragging and creating a windo allows you to select a few)
            * 2-3% of the full time was used for GC - because it's leveraging so much CPU capacity that we're not using and maintained a 4meg heap (really small)
* simplest solution to make this concurrent? fanout pattern, give each file its own goroutine (may not scale well)
    * `freqConcurrent` - use the goroutines for every file
    * use atomic number for race condition of the `found` metric
    * cache coherency problem: the found will be copied over to all cores and any update will cause latency (mark other copies as dirty)
        * so we can create a local found variable in the goroutine and write a defer function that writes the local found variable back to the original found
    * this was easy BECAUSE we already had the sequential version
* `freqNumCPU`:
    * extra level of complexity: we've added a channel now
    * this function is much more mechanically sympathetic because it's only writing to `found` the # of core times (8/16)
    * runs really well with a 40meg heap and the cpu balanced by the computer's hardware requirements

MemCPU: https://github.com/ardanlabs/gotraining/blob/master/topics/go/profiling/memcpu/stream.go 
* search the entire internet for "elvis" and capitalize the E
* gotip test -bench . -benchtime 3s -benchmem -memprofile m.out //the memprofile will give us a memory profile that we can use `pprof` to evaluate
    * this test also leaves a test binary - `gotip tool pprof [stream.test - only if you want binary instructions] m.out`
        * Type: alloc_space (other is live heap space)
    * `gotip tool pprof -noinlines m.out`: compiler optimizations
        * output will now matche the weblist default data (shows compiler optimizations) instead of the list default data (doesn't have compiler optimizations on)
        * `list algOne`:
            * line 83 and 89 are flat allocations - these two rows are causing this
    * to know why, we need to look at the compiler - ecape analysis report   
        * gotip test -bench . -benchtime 3s -benchmem -memprofile m.out --gcflags -m=2
        * line 83 (NewBuffer) now shows up in that compiler report: 
            * compiler says let's not make function call but instead take code out of function, inline it directly, and forget the function call
            * making a function call in go is very expensive - lots of things happen, stack grows, context switches, memory copying, etc.
            * if clockcycles mattered, you would write all code in one function - but the compiler is here to help us optimize this without having to call a function under the hood
            * also NewBuffer is using pointer semantics - heap allocation - if call gets inlined and there's no function call there is NOT an allocation

Scavenger: run in the background and release memory back to the os/program
    * originally it wasn't very aggressive (memory outages), so they rewrote it and now it's super aggressive
    * this is bad for GC trace output because it takes over the screen, so run: `GODEBUG=gctrace=1 ./project 2> >(grep -v 'scvg') > /dev/null`
* Debugging tool: https://github.com/ardanlabs/gotraining/tree/master/topics/go/profiling/project 
    * localhost:5000/debug/pprof/
    * gotip took pprof http://localhost:5000/debug/pprof//allocs will download that profile to the local
    * `top 40 -cum` -> gives cumulative allocation for top 4 functions

Other tools/frameworks? 
* bgo - lots of apps in china use this
* buffalo.io - the rails for go, good for web apps

Application design: https://github.com/ardanlabs/service 
* going to be making our own edits: https://github.com/meganfeichtel/service 
* starter kit for go dev projects - clone and run 
* writing a webservice (crud-based)
* every decision at a macro-level should be to handle bugs in production
* Go says: 
    * the source tree that you are putting together, you are no longer building a monolithic app where folders are used to utilize source code
    * you are building a static set of apis that come together to form an applications
    * every folder in the source tree that actually represents a static codebase - this package of code acts as a firewall (microservices)
    * every time we add a folder, what is this package/API's purpose? 
    * if there are packages called utils, common, package of types, etc - because that point of dependency is going to cause the project to not be able to grow
    * you want DISTINCT, CONCRETE, PYSHICAL apis
* Type system: 1 purpose - allow data to flow in and out of an API
    1. to flow in - based on what it is (concrete) or what it does (interface)
    2. to flow out - always returns the concrete data (does not pre-decouple data for the caller)
        * return type should not be an interface, the caller can do that for themselves
        * exception is error handling
* Less packages are more: start with larger packages and then discover where it could be broken down for simplicity/need
    * all developers at Go work out of 1 repo - why there is one GOPATH - now because of modules, we're not actualy bound to this anymore
    * it's also very opinionated _except_ about project structures 
        * make sure package you add on Monday, you would make the same exact decision of where to put it on Friday - or else very difficult to maintain a mental model
        * project structure has 3 parts:
            1. application layer packages - start up, shut down, request/response, maybe some containment
                * also policies (like logging)
            2. business layer - talking to dbs, biz rules
            3. foundational packages - marshalling
                * can't and shouldn't be logging
* for every project you are working on, bind it to a single repo (not 1 binary)
    * when we talk about microservices, they're solving productivity issues, so only break things up if velocity is slowing
    * hierarchy should serve one purpose: to make it easier to maintain an mental model of the code
    * 2 folders: 
        1. cmd/ - have other folders, one for each binary we're building, application layer packages
        2. internal/ - business layer packages, shouldn't have packages inside of packages






